{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "483dd542-7b6f-4d18-8571-5113ca7efd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm # 반복문의 진행상황 확인하는 모듈\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# 경고끄기 (option)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04018e6-d969-4f3d-90de-083715e03486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "category :  seong\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "디렉토리 없음\n"
     ]
    }
   ],
   "source": [
    "# 전역변수부\n",
    "# category = input('category : ')\n",
    "\n",
    "# image_path = f\"../crops/{category}/\" # crops된 이미지 경로\n",
    "# output_path = f\"../vector_frame/{category}/\" # npy파일 보관된 경로\n",
    "# if not os.path.exists(output_path):\n",
    "#     print('디렉토리가 없으므로 생성합니다.')\n",
    "#     os.mkdir(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31f42e22-ba8c-4e46-8acd-1a2a7760068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict():\n",
    "    category_model_dict = dict()\n",
    "\n",
    "    # 카테고리 별 모델은 변경될 수 있음\n",
    "    category_model_dict['wallet'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    category_model_dict['phone'] = ['Efficientnet_b0', 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2']\n",
    "    category_model_dict['cap']  = ['Efficientnet_lite0', 'https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2']\n",
    "    category_model_dict['card'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    category_model_dict['bag'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    category_model_dict['book'] = ['R101x3', 'https://tfhub.dev/google/bit/m-r101x3/1']\n",
    "    category_model_dict['shopping'] = ['Mobilenet_v2', 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4']\n",
    "    category_model_dict['electronics'] = ['R50x1_device', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/device/1']\n",
    "    category_model_dict['car_key'] = ['Efficientnet_lite0', 'https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2']\n",
    "    category_model_dict['shoes'] = ['Mobilenet_v2', 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4']\n",
    "    category_model_dict['document'] = ['R101x3', 'https://tfhub.dev/google/bit/m-r101x3/1']\n",
    "    category_model_dict['watch'] = ['Mobilenet_v2', 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4']\n",
    "     # 아래 카테고리들은 테스트 후 다시 모델 삽입 예정임 임시로 넣어 놈\n",
    "    category_model_dict['cloth'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/clothing/1']\n",
    "    category_model_dict['gloves'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/clothing/1']\n",
    "    category_model_dict['muffler'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/clothing/1']\n",
    "    category_model_dict['necklace'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    category_model_dict['ring'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    \n",
    "    return category_model_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2032d2d-5f57-4b49-87ff-4680e5c603a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(category):\n",
    "    # 카테고리를 입력받아 모델을 생성해서 모델명과 생성된 모델을 리턴함\n",
    "    model_dict = make_dict()\n",
    "    model_name = model_dict[category][0]\n",
    "    model_url = model_dict[category][1]\n",
    "    \n",
    "    layer = hub.KerasLayer(model_url, input_shape=(224, 224)+(3,))\n",
    "    model = tf.keras.Sequential([layer])\n",
    "    model.build([None, 244, 244, 3])\n",
    "    \n",
    "    return model_name, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5dcb6bd-059c-4a56-b90c-914aee18ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수부\n",
    "\n",
    "# 이미지 객체탐지\n",
    "def crop(images):\n",
    "    os.system(f\"python yolov5/detect.py --source {images} --weights yolov5/runs/train/cate_29_epoch10/weights/best.pt --conf 0.4 --save-crop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "190a9418-b408-4309-b23d-2df64c36b550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file):\n",
    "    file = Image.open(file).convert('RGB').resize((224, 224))\n",
    "    file = np.array(file)/255.0 # 정규화\n",
    "\n",
    "    embedding = model.predict(file[np.newaxis, ...])\n",
    "    feature_np = np.array(embedding)\n",
    "    flattened_feature = feature_np.flatten()\n",
    "\n",
    "    return flattened_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e223b955-18ce-4182-ad8e-a283273602c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe(category, model_name=model_name):\n",
    "    global output_path    \n",
    "    tmp_filename = np.load(output_path+f'{category}_filename({model_name}).npy', allow_pickle=True)\n",
    "    tmp_output = np.load(output_path+f'{category}_output({model_name}).npy', allow_pickle=True)\n",
    "    df = pd.DataFrame({'filename':tmp_filename, 'output':tmp_output})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49773b58-c853-49d1-a49e-167e8657de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(file, category, metric='cosine'):\n",
    "    before_time = time.time()\n",
    "    file2vec = extract(file) # 이미지 벡터화\n",
    "    df = get_dataframe(category) # 데이터프레임 가져오기\n",
    "    df = df.append({'filename':file, 'output':file2vec}, ignore_index=True)\n",
    "    \n",
    "    cos_sim_array = np.zeros((len(df)))\n",
    "    for i in range(0, len(df)):\n",
    "        cos_sim_array[i] = distance.cdist([file2vec] , [df.iloc[i, 1]], metric)[0] # 벡터화된 이미지 기준\n",
    "    df['cos_sim']=cos_sim_array\n",
    "    after_time = time.time()\n",
    "    runtime = after_time-before_time\n",
    "    return df, runtime # 런타임 비교용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7915b32b-88b0-4304-9b7e-2fbb6a988b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop된 파일을 인풋 파일으로 넣어줘야함\n",
    "def search_img(category, cropped_file, threshold=0.4):\n",
    "    global image_path\n",
    "    global output_path\n",
    "    cos_sim_df, runtime = get_cos_sim(cropped_file, category=category)\n",
    "    df_top_sim = cos_sim_df[cos_sim_df.cos_sim <= threshold].sort_values(by='cos_sim')[:50]\n",
    "    \n",
    "    return df_top_sim.filename.values                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49a01b69-f1e1-4f29-b4e6-27d19f898a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "category : phone\n",
      "image_path : /Users/iseongmin/workspaces/project2/crops/phone/F2022030100000776-1.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-13 15:42:41.661512: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 985ms/step\n",
      "['/Users/iseongmin/workspaces/project2/crops/phone/F2022030100000776-1.jpg'\n",
      " 'F2022030100000776-1.jpg' 'V0001519H08300012-1.jpg'\n",
      " 'F2022071100003300-1.jpg' 'F2022031900001092-1.jpg'\n",
      " 'F2022030400001346-1.jpg' 'F2022070100000328-1.jpg'\n",
      " 'F2022051200004143-1.jpg' 'F2022030200002610-1.jpg'\n",
      " 'F2022031300000505-1.jpg' 'F2022042400000492-1.jpg'\n",
      " 'F2022052500001108-1.jpg' 'F2022042900000890-1.jpg'\n",
      " 'V0003606H08160018-1.jpg' 'F2022080800002453-1.jpg'\n",
      " 'F2022080800002725-1.jpg' 'F2022052900002052-1.jpg'\n",
      " 'F2022083000002644-1.jpg' 'F2022070700001254-1.jpg'\n",
      " 'F2022071200001179-1.jpg' 'F2022052000002517-1.jpg'\n",
      " 'F2022062800003695-1.jpg' 'F2022071400000283-1.jpg'\n",
      " 'F2022082600002411-1.jpg']\n",
      "소요시간 : 9.779초\n"
     ]
    }
   ],
   "source": [
    "# 메인\n",
    "if __name__ == '__main__':\n",
    "    # crop(input_file) # 인풋파일 잘라내기 + 카테고리 판단해주기\n",
    "    category = input('category :') # 카테고리 이미지 전달\n",
    "    input_file = input('image_path :') # 입력 이미지 전달\n",
    "    start_time = time.time()\n",
    "    image_path = f\"../crops/{category}/\" # crops된 이미지 경로\n",
    "    output_path = f\"../vector_frame/{category}/\" # npy파일 보관된 경로\n",
    "    if not os.path.exists(output_path):\n",
    "        print('디렉토리가 없으므로 생성합니다.')\n",
    "        os.mkdir(output_path)\n",
    "    \n",
    "    model_name, model = select_model(category)\n",
    "    \n",
    "    # threshold의 디폴트 값은 0.4이고, search_img 함수의 마지막 인자로 넣어주면 바꿀 수 있음\n",
    "    print(search_img(category, input_file)) # 인자로 input_file이 아닌 crops된 파일의 경로로 바꿔줘야함\n",
    "    print(f'소요시간 : {time.time() - start_time:.3f}초') # 테스트용 코드 -> 추후 삭제 ㄱ\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "4409adf0-ad7c-4554-8ba5-52cd0868c686",
   "metadata": {},
   "source": [
    "/Users/iseongmin/workspaces/project2/crops/phone/F2022030100000776-1.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aed53a-2853-427a-a1ce-79d7a54bf968",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_p38",
   "language": "python",
   "name": "tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
