{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf2edf0f-cf43-414e-8c30-97b31776fdf0",
   "metadata": {},
   "source": [
    "# 크롤링 모델 자동화\n",
    "1. [크롤링된 이미지 입력]\n",
    "2. [yolo로 객체탐지]\n",
    "3. 객체 탐지 되면 카테고리 값을 전달 받아야함\n",
    "    - 혹은 사용자로부터 카테고리 값을 입력 받음\n",
    "4. 입력받은 카테고리 값으로 모델 매칭 -> 모델 url가져오기\n",
    "5. 해당 카테고리의 모델 사용해서 벡터화\n",
    "    - 처음 구동 시 전체 crops 폴더의 값을 다 가져와서 make_dateframe() 돌려서 npy 저장까지\n",
    "    - n회차 구동 시 vector_frame에 있는 npy파일 가져오기, 크롤링된 이미지만 벡터화해서 append후 npy 저장\n",
    "6. 카테고리 값은?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5a1a8ad-eb49-4f96-b8a1-fe589544f4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈 불러오기\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm # 반복문의 진행상황 확인하는 모듈\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# 경고끄기 (option)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f9186f3-761f-4d28-b0dd-9c915fbc2939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "category : phone\n"
     ]
    }
   ],
   "source": [
    "category = input('category :') # category는 사용자가 선택 하거나 탐지된 값을 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9153bf-ec7a-41db-b3e2-7f7dcba93c09",
   "metadata": {},
   "source": [
    "## 4. 입력받은 카테고리 값으로 모델 매칭 -> 모델 url 가져오기\n",
    "1. 딕셔너리 형태로 카테고리 : [모델명, 모델 url]\n",
    "    - 카테고리를 key로, 모델명과 모델url을 value로 만들기\n",
    "- __모델명 작성법__ : <br>\n",
    "    a. 첫번째 문자만 대문자 나머지는 소문자 사용<br>\n",
    "    b. 띄어쓰기는 _로 사용<br>\n",
    "    c. bit_m 모델같은 경우 R50x1_object 등으로 모델명_파인튜닝대상 으로 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fc6839-19a8-4fa8-b1e5-4ff36f28b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict():\n",
    "    category_model_dict = dict()\n",
    "\n",
    "    # 카테고리 별 모델은 변경될 수 있음\n",
    "    category_model_dict['wallet'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    category_model_dict['phone'] = ['Efficientnet_b0', 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2']\n",
    "    category_model_dict['cap']  = ['Efficientnet_lite0', 'https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2']\n",
    "    category_model_dict['card'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    category_model_dict['bag'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    category_model_dict['book'] = ['R101x3', 'https://tfhub.dev/google/bit/m-r101x3/1']\n",
    "    category_model_dict['shopping'] = ['Mobilenet_v2', 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4']\n",
    "    category_model_dict['electronics'] = ['R50x1_device', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/device/1']\n",
    "    category_model_dict['car_key'] = ['Efficientnet_lite0', 'https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2']\n",
    "    category_model_dict['shoes'] = ['Mobilenet_v2', 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4']\n",
    "    category_model_dict['document'] = ['R101x3', 'https://tfhub.dev/google/bit/m-r101x3/1']\n",
    "    category_model_dict['watch'] = ['Mobilenet_v2', 'https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4']\n",
    "     # 아래 카테고리들은 테스트 후 다시 모델 삽입 예정임 임시로 넣어 놈\n",
    "    category_model_dict['cloth'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/clothing/1']\n",
    "    category_model_dict['gloves'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/clothing/1']\n",
    "    category_model_dict['muffler'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/clothing/1']\n",
    "    category_model_dict['necklace'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    category_model_dict['ring'] = ['R50x1_object', 'https://tfhub.dev/google/experts/bit/r50x1/in21k/object/1']\n",
    "    \n",
    "    return category_model_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9d53f41-99c1-417f-bb6a-36cf6bbcfb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_model(category, image_shape):\n",
    "    # 카테고리를 입력받아 모델을 생성해서 모델명과 생성된 모델을 리턴함\n",
    "    model_dict = make_dict()\n",
    "    model_name = model_dict[category][0]\n",
    "    model_url = model_dict[category][1]\n",
    "    \n",
    "    layer = hub.KerasLayer(model_url, input_shape=IMAGE_SHAPE+(3,))\n",
    "    model = tf.keras.Sequential([layer])\n",
    "    model.build([None, 244, 244, 3])\n",
    "    \n",
    "    return model_name, model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56c650-4afb-474c-99d0-43d767adf673",
   "metadata": {},
   "source": [
    "5. 해당 카테고리의 모델 사용해서 벡터화\n",
    "    - extract 함수 만들기\n",
    "    - 처음 구동 시 전체 crops 폴더의 값을 다 가져와서 make_dateframe() 돌려서 npy 저장까지\n",
    "    - n회차 구동 시 vector_frame에 있는 npy파일 가져오기, 크롤링된 이미지만 벡터화해서 append후 npy 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0921f2-a1d8-4581-bbc0-8dcf73380a21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow2_p38",
   "language": "python",
   "name": "tensorflow2_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
